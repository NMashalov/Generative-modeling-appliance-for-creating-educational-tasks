Нейронные сети представляют собой вычислительные модели, состоящие из узлов, называемых нейронами, организованных в слои. Каждый нейрон взвешивает входные сигналы, представленные как вектор \( \mathbf{x} = (x_1, x_2, ..., x_n) \), с весами \( \mathbf{w} = (w_1, w_2, ..., w_n) \) и смещением \( b \), где \( n \) - количество входов, \( x_i \) - \( i \)-й входной сигнал, \( w_i \) - весовой коэффициент \( i \)-го входа, \( b \) - смещение (bias). На выходе нейрона производится линейная комбинация входов с весами и смещением:

\[ z = \sum_{i=1}^{n} w_i x_i + b \]

Полученная сумма \( z \) затем подвергается нелинейному преобразованию при помощи функции активации \( f(z) \), которая определяет активацию нейрона:

\[ y = f(z) \]

Функция активации обычно вводится для добавления нелинейности в модель, что позволяет нейронной сети моделировать сложные нелинейные зависимости в данных. Некоторые из распространенных функций активации включают в себя сигмоидальную функцию (\( \sigma \)), гиперболический тангенс (\( \tanh \)), ReLU (Rectified Linear Unit) и их вариации.

В случае многослойной нейронной сети, выходы нейронов одного слоя становятся входами для следующего слоя, образуя цепочку преобразований. Процесс передачи данных через нейроны последовательных слоев называется прямым распространением (forward propagation).

Нейронные сети обучаются путем настройки весов \( \mathbf{w} \) и смещений \( b \) с использованием алгоритмов оптимизации, таких как градиентный спуск. Во время обучения модель минимизирует функцию потерь \( L \), которая оценивает разницу между предсказанным результатом и истинным значением:

\[ L = \frac{1}{N} \sum_{i=1}^{N} L(y_i, \hat{y}_i) \]

где \( N \) - количество обучающих примеров, \( y_i \) - истинное значение, \( \hat{y}_i \) - предсказанное значение.


\subsection{Модель Хопфилда}

Модель Хопфилда - это нейронная сеть, предложенная Джоном Хопфилдом в 1982 году, которая является одним из первых примеров рекуррентных нейронных сетей и используется для моделирования ассоциативной памяти и ассоциативного запоминания. Эта модель вдохновлена концепцией обработки информации в мозге и базируется на принципе ассоциативного запоминания, который подразумевает возможность восстановления целевого образа (или паттерна) по части информации.

В модели Хопфилда каждый нейрон представляет собой двоичный (или биполярный) элемент, который может находиться в одном из двух состояний: активном (1) или неактивном (0). Нейроны соединены сетью симметричных связей, где каждая связь имеет ассоциативную силу между соответствующими нейронами. Эта сеть связей может быть представлена в виде симметричной матрицы весов, где элементы \(w_{ij}\) обозначают силу связи между нейронами \(i\) и \(j\).

Динамика модели Хопфилда определяется обновлением активации каждого нейрона в соответствии с функцией активации и правилом Хопфилда:

1. **Инициализация**: Начнем с заданного начального состояния нейронов.

2. **Обновление нейронов**: Нейроны обновляются параллельно и асинхронно на основе правила Хопфилда:
   \[ s_i(t+1) = \text{sign}\left(\sum_j w_{ij} s_j(t)\right) \]

3. **Повторение шага 2**: Процесс обновления нейронов повторяется до тех пор, пока система не стабилизируется в некотором состоянии или пока не произойдет сходимость к сохраненным паттернам.

Одно из ключевых свойств модели Хопфилда - это способность к ассоциативному запоминанию. После обучения модель способна восстанавливать сохраненные образы при предъявлении искаженных или неполных версий этих образов. Это происходит благодаря тому, что система восстанавливается к ближайшему сохраненному образу в пространстве состояний.

Модель Хопфилда была активно изучена как теоретически, так и экспериментально, и она оказала влияние на развитие нейроинформатики и ассоциативного запоминания. Она также служит основой для более сложных и глубоких моделей нейронных сетей, используемых в современных исследованиях машинного обучения и искусственного интеллекта.
